{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**A Pythonic Guide to PyTorch & Computer Vision**\n",
        "\n",
        "This notebook will cover:\n",
        "Setting up our environment.\n",
        "\n",
        "*  The core data pipeline: Dataset, Transform, and DataLoader.\n",
        "\n",
        "*  Defining a model using nn.Module.\n",
        "\n",
        "\n",
        "*   The standard training loop (forward pass, loss, backward pass, optimizer step).\n",
        "\n",
        "*   The standard evaluation loop.\n"
      ],
      "metadata": {
        "id": "O9LVf0Z7HOK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup and Imports\n",
        "# We'll need torch for all the core deep learning functionality,\n",
        "# nn for building blocks of networks, optim for optimizers,\n",
        "# and torchvision for datasets, transforms, and pre-trained models.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Check for GPU and set device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# This is the expected output if you are on a Colab notebook with a GPU runtime.\n",
        "# If you see \"cpu\", go to Runtime > Change runtime type and select \"GPU\".\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "aUQRfYDRHoLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data (Transforms, Datasets, and DataLoaders)"
      ],
      "metadata": {
        "id": "1LktIWtQMkKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformations.\n",
        "# transforms.ToTensor() converts images from PILImage format to PyTorch Tensors.\n",
        "# transforms.Normalize() adjusts the pixel values. The two tuples are the means\n",
        "# and standard deviations for the 3 color channels (R, G, B). These specific\n",
        "# values are the standard pre-calculated ones for the CIFAR-10 dataset.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    #transforms.RandomRotation(degrees=(0, 180)),\n",
        "    #transforms.RandomPerspective(distortion_scale=0.6, p=1.0)\n",
        "])\n",
        "\n",
        "# Define the batch size. This is how many images we process at once.\n",
        "batch_size = 64\n",
        "\n",
        "# Download and load the training data.\n",
        "# `root='./data'` is where the data will be stored.\n",
        "# `train=True` specifies the training set.\n",
        "# `download=True` will download it if it's not already there.\n",
        "# `transform=transform` applies our pre-processing pipeline.\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "# Download and load the testing data.\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the human-readable class names for CIFAR-10\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "f5atuv5QLat0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Visualize a Batch of Data**"
      ],
      "metadata": {
        "id": "N9EZnxXiMTrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "    \"\"\"Helper function to un-normalize and display an image\"\"\"\n",
        "    img = img / 2 + 0.5  # Un-normalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Get one random batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images in a grid\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# Print the labels for the images shown\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "U598-dqgLcqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Define the Neural Network (nn.Module)**"
      ],
      "metadata": {
        "id": "A4hWWnHAMYzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 3 input image channels (R,G,B), 16 output channels, 3x3 square convolution\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2) # 2x2 max pooling\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "\n",
        "        # The size calculation for the linear layer can be tricky.\n",
        "        # Images start at 32x32.\n",
        "        # After one pool layer -> 16x16.\n",
        "        # After a second pool layer -> 8x8.\n",
        "        # So the flattened size is 32 (output channels of conv2) * 8 * 8.\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, 10) # 10 output classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 16, 16, 16\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 32, 8, 8\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch -> n, 2048\n",
        "        x = F.relu(self.fc1(x)) # -> n, 256\n",
        "        x = self.fc2(x) # -> n, 10\n",
        "        return x"
      ],
      "metadata": {
        "id": "ausTfSGNLzzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Instantiate Model, Loss Function, and Optimizer**"
      ],
      "metadata": {
        "id": "QzBkXYeIMOZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model and move it to the GPU\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "7behY0ouL1LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. The Training Loop**"
      ],
      "metadata": {
        "id": "gfaard4CMGXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "\n",
        "# Set the number of epochs (passes through the training data)\n",
        "num_epochs = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # Get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # 1. Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # 3. Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 4. Backward pass (calculate gradients)\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Update weights (take a step with the optimizer)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:    # Print every 100 mini-batches\n",
        "            print(f'[Epoch {epoch + 1}, Batch {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "s8bTcFJkL4vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. The Testing/Evaluation Loop**"
      ],
      "metadata": {
        "id": "biQYY8x3MBME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Since we're not training, we don't need to calculate gradients\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Get model outputs (forward pass)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # The class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f} %')"
      ],
      "metadata": {
        "id": "6W6QYROHL6g6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
